{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eb8b49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, confusion_matrix,\n",
    "    precision_recall_curve, roc_curve, auc, classification_report\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import re\n",
    "import emoji\n",
    "from transformers import (\n",
    "    DistilBertForSequenceClassification, \n",
    "    AutoTokenizer,\n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from transformers.integrations import WandbCallback\n",
    "import optuna\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Check for MPS (Apple Silicon) device\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device = torch.device('mps' if use_mps else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "NUM_LABELS = 2  # Binary classification\n",
    "OUTPUT_DIR = \"./results\"\n",
    "MODEL_DIR = \"./saved_model\"\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace URLs with token\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '[URL]', text)\n",
    "    \n",
    "    # Replace user mentions with token\n",
    "    text = re.sub(r'@\\w+', '[USER]', text)\n",
    "    \n",
    "    # Replace hashtags with token but keep the text\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    \n",
    "    # Convert emojis to text\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    # Replace repeated characters (e.g., \"coooool\" -> \"cool\")\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Data preparation\n",
    "def prepare_data(df):\n",
    "    # Apply preprocessing to tweets\n",
    "    df['tweet'] = df['tweet'].astype(str).apply(preprocess_text)\n",
    "    df['label'] = df['class'].apply(lambda x: 0 if x == 2 else 1)\n",
    "    print(df['label'].value_counts())\n",
    "    df.drop(columns=['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither', 'class'], inplace=True)\n",
    "\n",
    "    # Calculate class weights for imbalanced dataset\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(df[\"label\"]),\n",
    "        y=df[\"label\"]\n",
    "    )\n",
    "    \n",
    "    class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "    print(f\"Class weights: {class_weight_dict}\")\n",
    "    \n",
    "    return df, class_weight_dict\n",
    "\n",
    "# Memory-efficient dataset implementation\n",
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize on-the-fly instead of storing all tokenized data in memory\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Remove batch dimension added by tokenizer when return_tensors=\"pt\"\n",
    "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        \n",
    "        encoding[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return encoding\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, \n",
    "        predictions, \n",
    "        average=\"binary\", \n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "    \n",
    "    # Calculate ROC AUC\n",
    "    fpr, tpr, _ = roc_curve(labels, probs[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"true_positives\": tp,\n",
    "        \"false_negatives\": fn,\n",
    "        \"false_positives\": fp,\n",
    "        \"true_negatives\": tn,\n",
    "        \"roc_auc\": roc_auc\n",
    "    }\n",
    "\n",
    "# Hyperparameter optimization using Optuna\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to search\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.001, 0.1, log=True)\n",
    "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.05, 0.2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16])\n",
    "    \n",
    "    # Define training arguments for this trial\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{OUTPUT_DIR}/trial_{trial.number}\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        logging_dir=f\"./logs/trial_{trial.number}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        report_to=\"none\",\n",
    "        dataloader_num_workers=0,\n",
    "        seed=RANDOM_SEED,\n",
    "        optim=\"adamw_torch\"\n",
    "    )\n",
    "    \n",
    "    # Initialize model for this trial\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, \n",
    "        num_labels=NUM_LABELS,\n",
    "        id2label={0: \"not offensive\", 1: \"offensive\"}\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate model\n",
    "    metrics = trainer.evaluate()\n",
    "    \n",
    "    return metrics[\"eval_f1\"]\n",
    "\n",
    "# Custom threshold prediction function\n",
    "def predict_with_threshold(model, tokenizer, text, threshold=0.5):\n",
    "    # Preprocess text\n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        processed_text, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True, \n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the right device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits.cpu()\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Apply custom threshold\n",
    "    prediction = 1 if probabilities[0][1].item() > threshold else 0\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"processed_text\": processed_text,\n",
    "        \"class_name\": model.config.id2label[prediction],\n",
    "        \"confidence\": probabilities[0][prediction].item(),\n",
    "        \"offensive_probability\": probabilities[0][1].item()\n",
    "    }\n",
    "\n",
    "# Error analysis function\n",
    "def analyze_errors(model, tokenizer, texts, true_labels, threshold=0.5):\n",
    "    results = []\n",
    "    \n",
    "    for text, true_label in zip(texts, true_labels):\n",
    "        prediction = predict_with_threshold(model, tokenizer, text, threshold)\n",
    "        pred_label = 1 if prediction[\"offensive_probability\"] > threshold else 0\n",
    "        \n",
    "        if pred_label != true_label:\n",
    "            results.append({\n",
    "                \"text\": text,\n",
    "                \"processed_text\": prediction[\"processed_text\"],\n",
    "                \"true_label\": true_label,\n",
    "                \"predicted_label\": pred_label,\n",
    "                \"offensive_probability\": prediction[\"offensive_probability\"]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Model explainability function\n",
    "def explain_prediction(model, tokenizer, text, explainer):\n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    def predict_fn(texts):\n",
    "        results = []\n",
    "        for t in texts:\n",
    "            inputs = tokenizer(\n",
    "                t,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=MAX_LENGTH,\n",
    "                padding=\"max_length\"\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                outputs = model(**inputs)\n",
    "            \n",
    "            logits = outputs.logits.cpu().numpy()\n",
    "            probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "            results.append(probs)\n",
    "        \n",
    "        return np.vstack(results)\n",
    "    \n",
    "    # Generate explanation\n",
    "    exp = explainer.explain_instance(\n",
    "        processed_text, \n",
    "        predict_fn, \n",
    "        num_features=10, \n",
    "        num_samples=1000,\n",
    "        labels=(1,)  # Explain offensive class\n",
    "    )\n",
    "    \n",
    "    return exp\n",
    "\n",
    "# Find optimal classification threshold\n",
    "def find_optimal_threshold(model, tokenizer, texts, true_labels):\n",
    "    probabilities = []\n",
    "    \n",
    "    for text in texts:\n",
    "        prediction = predict_with_threshold(model, tokenizer, text, threshold=0.5)\n",
    "        probabilities.append(prediction[\"offensive_probability\"])\n",
    "    \n",
    "    # Calculate precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(true_labels, probabilities)\n",
    "    \n",
    "    # Calculate F1 score for each threshold\n",
    "    f1_scores = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "    \n",
    "    # Find threshold with highest F1 score\n",
    "    best_threshold_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_threshold_idx]\n",
    "    \n",
    "    # Plot precision-recall curve\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve (Best threshold: {best_threshold:.3f})')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('precision_recall_curve.png')\n",
    "    \n",
    "    return best_threshold\n",
    "\n",
    "# Main training pipeline\n",
    "def main(df):\n",
    "    # Prepare data\n",
    "    processed_df, class_weights = prepare_data(df)\n",
    "    \n",
    "    # Create stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    fold_results = []\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(processed_df[\"tweet\"], processed_df[\"label\"])):\n",
    "        print(f\"Training fold {fold+1}/5...\")\n",
    "        \n",
    "        # Split data\n",
    "        train_texts = processed_df[\"tweet\"].iloc[train_idx].reset_index(drop=True)\n",
    "        train_labels = processed_df[\"label\"].iloc[train_idx].reset_index(drop=True).to_numpy()\n",
    "        val_texts = processed_df[\"tweet\"].iloc[val_idx].reset_index(drop=True)\n",
    "        val_labels = processed_df[\"label\"].iloc[val_idx].reset_index(drop=True).to_numpy()\n",
    "        \n",
    "        # Create datasets\n",
    "        global train_dataset, val_dataset  # Make them accessible to the objective function\n",
    "        train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
    "        val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LENGTH)\n",
    "        \n",
    "        # Hyperparameter optimization if this is first fold\n",
    "        if fold == 0:\n",
    "            print(\"Optimizing hyperparameters...\")\n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            study.optimize(objective, n_trials=5)  # Reduced trials for limited compute\n",
    "            \n",
    "            best_params = study.best_params\n",
    "            print(f\"Best hyperparameters: {best_params}\")\n",
    "        \n",
    "        # Train with best hyperparameters\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"{OUTPUT_DIR}/fold_{fold}\",\n",
    "            num_train_epochs=5,\n",
    "            per_device_train_batch_size=best_params[\"batch_size\"],\n",
    "            per_device_eval_batch_size=best_params[\"batch_size\"] * 2,\n",
    "            gradient_accumulation_steps=4,\n",
    "            warmup_ratio=best_params[\"warmup_ratio\"],\n",
    "            learning_rate=best_params[\"learning_rate\"],\n",
    "            weight_decay=best_params[\"weight_decay\"],\n",
    "            logging_dir=f\"./logs/fold_{fold}\",\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            save_total_limit=1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            greater_is_better=True,\n",
    "            report_to=\"none\",\n",
    "            dataloader_num_workers=0,\n",
    "            seed=RANDOM_SEED,\n",
    "            optim=\"adamw_torch\"\n",
    "        )\n",
    "        \n",
    "        # Initialize model with class weights\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME, \n",
    "            num_labels=NUM_LABELS,\n",
    "            id2label={0: \"not offensive\", 1: \"offensive\"}\n",
    "        )\n",
    "        \n",
    "        # Set class weights in model config\n",
    "        model.config.class_weights = class_weights\n",
    "        \n",
    "        # Initialize trainer with early stopping\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        trainer.train()\n",
    "        \n",
    "        # Evaluate model\n",
    "        metrics = trainer.evaluate()\n",
    "        fold_results.append(metrics)\n",
    "        \n",
    "        # Save model for this fold\n",
    "        trainer.save_model(f\"{MODEL_DIR}/fold_{fold}\")\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_optimal_threshold(\n",
    "            model, tokenizer, val_texts, val_labels\n",
    "        )\n",
    "        print(f\"Optimal threshold for fold {fold+1}: {optimal_threshold:.3f}\")\n",
    "        \n",
    "        # Error analysis on validation set\n",
    "        error_df = analyze_errors(\n",
    "            model, tokenizer, val_texts, val_labels, threshold=optimal_threshold\n",
    "        )\n",
    "        \n",
    "        # Save error analysis\n",
    "        if not error_df.empty:\n",
    "            error_df.to_csv(f\"error_analysis_fold_{fold}.csv\", index=False)\n",
    "            print(f\"Saved error analysis for fold {fold+1} with {len(error_df)} misclassified examples\")\n",
    "        \n",
    "        # Create LIME explainer\n",
    "        explainer = LimeTextExplainer(class_names=[\"not offensive\", \"offensive\"])\n",
    "        \n",
    "        # Explain some misclassifications\n",
    "        if not error_df.empty:\n",
    "            # Get up to 5 examples of each error type (FP and FN)\n",
    "            false_positives = error_df[error_df[\"true_label\"] == 0].head(5)\n",
    "            false_negatives = error_df[error_df[\"true_label\"] == 1].head(5)\n",
    "            \n",
    "            # Explain false positives\n",
    "            print(\"\\nExplaining false positives:\")\n",
    "            for idx, row in false_positives.iterrows():\n",
    "                exp = explain_prediction(model, tokenizer, row[\"text\"], explainer)\n",
    "                print(f\"\\nText: {row['text']}\")\n",
    "                print(\"Features contributing to 'offensive' classification:\")\n",
    "                exp.as_list(label=1)\n",
    "                \n",
    "            # Explain false negatives\n",
    "            print(\"\\nExplaining false negatives:\")\n",
    "            for idx, row in false_negatives.iterrows():\n",
    "                exp = explain_prediction(model, tokenizer, row[\"text\"], explainer)\n",
    "                print(f\"\\nText: {row['text']}\")\n",
    "                print(\"Features contributing to 'offensive' classification:\")\n",
    "                exp.as_list(label=1)\n",
    "        \n",
    "    # Average results across folds\n",
    "    avg_results = {\n",
    "        metric: np.mean([fold[f\"eval_{metric}\"] for fold in fold_results])\n",
    "        for metric in fold_results[0].keys() if metric.startswith(\"eval_\")\n",
    "    }\n",
    "    \n",
    "    print(\"\\nAverage results across folds:\")\n",
    "    for metric, value in avg_results.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Train final model on all data\n",
    "    print(\"\\nTraining final model on all data...\")\n",
    "    \n",
    "    # Create datasets\n",
    "    all_texts = processed_df[\"tweet\"].reset_index(drop=True)\n",
    "    all_labels = processed_df[\"label\"].reset_index(drop=True).to_numpy()\n",
    "    full_dataset = TweetDataset(all_texts, all_labels, tokenizer, MAX_LENGTH)\n",
    "    \n",
    "    # Training arguments for final model\n",
    "    final_training_args = TrainingArguments(\n",
    "        output_dir=f\"{OUTPUT_DIR}/final\",\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=best_params[\"batch_size\"],\n",
    "        per_device_eval_batch_size=best_params[\"batch_size\"] * 2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_ratio=best_params[\"warmup_ratio\"],\n",
    "        learning_rate=best_params[\"learning_rate\"],\n",
    "        weight_decay=best_params[\"weight_decay\"],\n",
    "        logging_dir=\"./logs/final\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        report_to=\"none\",\n",
    "        dataloader_num_workers=0,\n",
    "        seed=RANDOM_SEED,\n",
    "        optim=\"adamw_torch\"\n",
    "    )\n",
    "    \n",
    "    # Initialize final model\n",
    "    final_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, \n",
    "        num_labels=NUM_LABELS,\n",
    "        id2label={0: \"not offensive\", 1: \"offensive\"}\n",
    "    )\n",
    "    \n",
    "    # Set class weights in model config\n",
    "    final_model.config.class_weights = class_weights\n",
    "    \n",
    "    # Initialize trainer\n",
    "    final_trainer = Trainer(\n",
    "        model=final_model,\n",
    "        args=final_training_args,\n",
    "        train_dataset=full_dataset\n",
    "    )\n",
    "    \n",
    "    # Train final model\n",
    "    final_trainer.train()\n",
    "    \n",
    "    # Save final model and tokenizer\n",
    "    final_trainer.save_model(MODEL_DIR)\n",
    "    tokenizer.save_pretrained(MODEL_DIR)\n",
    "    \n",
    "    # Return final model and tokenizer\n",
    "    return final_model, tokenizer, optimal_threshold\n",
    "\n",
    "# Function to load saved model and make predictions\n",
    "def load_model_and_predict(text, threshold=None):\n",
    "    # Load model and tokenizer\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "    \n",
    "    # Use default threshold if none provided\n",
    "    if threshold is None:\n",
    "        # Try to load threshold from config\n",
    "        if hasattr(model.config, \"threshold\"):\n",
    "            threshold = model.config.threshold\n",
    "        else:\n",
    "            threshold = 0.5\n",
    "    \n",
    "    # Make prediction\n",
    "    return predict_with_threshold(model, tokenizer, text, threshold)\n",
    "\n",
    "# Usage example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4481a8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-05 19:48:03,092] A new study created in memory with name: no-name-13a707c9-a70b-4182-abb3-b0dc589562e6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    20620\n",
      "0     4163\n",
      "Name: count, dtype: int64\n",
      "Class weights: {0: np.float64(2.9765793898630797), 1: np.float64(0.6009456838021339)}\n",
      "Training fold 1/5...\n",
      "Optimizing hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1857' max='1857' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1857/1857 37:48, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.118990</td>\n",
       "      <td>0.962074</td>\n",
       "      <td>0.977112</td>\n",
       "      <td>0.981174</td>\n",
       "      <td>0.973084</td>\n",
       "      <td>4013</td>\n",
       "      <td>111</td>\n",
       "      <td>77</td>\n",
       "      <td>756</td>\n",
       "      <td>0.986760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.127992</td>\n",
       "      <td>0.962074</td>\n",
       "      <td>0.977328</td>\n",
       "      <td>0.972169</td>\n",
       "      <td>0.982541</td>\n",
       "      <td>4052</td>\n",
       "      <td>72</td>\n",
       "      <td>116</td>\n",
       "      <td>717</td>\n",
       "      <td>0.988772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.135917</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.978358</td>\n",
       "      <td>0.975645</td>\n",
       "      <td>0.981086</td>\n",
       "      <td>4046</td>\n",
       "      <td>78</td>\n",
       "      <td>101</td>\n",
       "      <td>732</td>\n",
       "      <td>0.987982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [310/310 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-05 20:26:40,752] Trial 0 finished with value: 0.9783581187280861 and parameters: {'learning_rate': 2.512256003028559e-05, 'weight_decay': 0.006625771682625362, 'warmup_ratio': 0.06075416218145075, 'batch_size': 8}. Best is trial 0 with value: 0.9783581187280861.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='930' max='930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [930/930 32:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.111312</td>\n",
       "      <td>0.961872</td>\n",
       "      <td>0.976926</td>\n",
       "      <td>0.983772</td>\n",
       "      <td>0.970175</td>\n",
       "      <td>4001</td>\n",
       "      <td>123</td>\n",
       "      <td>66</td>\n",
       "      <td>767</td>\n",
       "      <td>0.986523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.122438</td>\n",
       "      <td>0.958846</td>\n",
       "      <td>0.975439</td>\n",
       "      <td>0.968675</td>\n",
       "      <td>0.982299</td>\n",
       "      <td>4051</td>\n",
       "      <td>73</td>\n",
       "      <td>131</td>\n",
       "      <td>702</td>\n",
       "      <td>0.987618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.117192</td>\n",
       "      <td>0.959451</td>\n",
       "      <td>0.975681</td>\n",
       "      <td>0.973678</td>\n",
       "      <td>0.977692</td>\n",
       "      <td>4032</td>\n",
       "      <td>92</td>\n",
       "      <td>109</td>\n",
       "      <td>724</td>\n",
       "      <td>0.987771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='155' max='155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [155/155 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-05 21:00:24,596] Trial 1 finished with value: 0.9769258942742034 and parameters: {'learning_rate': 3.1055633434462665e-05, 'weight_decay': 0.01846408599524658, 'warmup_ratio': 0.19525356785255102, 'batch_size': 16}. Best is trial 0 with value: 0.9783581187280861.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='930' max='930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [930/930 33:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109733</td>\n",
       "      <td>0.962679</td>\n",
       "      <td>0.977425</td>\n",
       "      <td>0.983788</td>\n",
       "      <td>0.971145</td>\n",
       "      <td>4005</td>\n",
       "      <td>119</td>\n",
       "      <td>66</td>\n",
       "      <td>767</td>\n",
       "      <td>0.986077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.129349</td>\n",
       "      <td>0.957837</td>\n",
       "      <td>0.974907</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.984481</td>\n",
       "      <td>4060</td>\n",
       "      <td>64</td>\n",
       "      <td>145</td>\n",
       "      <td>688</td>\n",
       "      <td>0.987285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.115140</td>\n",
       "      <td>0.961670</td>\n",
       "      <td>0.977009</td>\n",
       "      <td>0.975121</td>\n",
       "      <td>0.978904</td>\n",
       "      <td>4037</td>\n",
       "      <td>87</td>\n",
       "      <td>103</td>\n",
       "      <td>730</td>\n",
       "      <td>0.987655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='155' max='155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [155/155 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-05 21:34:54,089] Trial 2 finished with value: 0.9774252593044539 and parameters: {'learning_rate': 2.260488650455323e-05, 'weight_decay': 0.09145433035559289, 'warmup_ratio': 0.1921180732300645, 'batch_size': 16}. Best is trial 0 with value: 0.9783581187280861.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='930' max='930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [930/930 33:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109293</td>\n",
       "      <td>0.960460</td>\n",
       "      <td>0.976179</td>\n",
       "      <td>0.978558</td>\n",
       "      <td>0.973812</td>\n",
       "      <td>4016</td>\n",
       "      <td>108</td>\n",
       "      <td>88</td>\n",
       "      <td>745</td>\n",
       "      <td>0.986124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.124124</td>\n",
       "      <td>0.957232</td>\n",
       "      <td>0.974556</td>\n",
       "      <td>0.964829</td>\n",
       "      <td>0.984481</td>\n",
       "      <td>4060</td>\n",
       "      <td>64</td>\n",
       "      <td>148</td>\n",
       "      <td>685</td>\n",
       "      <td>0.987145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.110447</td>\n",
       "      <td>0.961670</td>\n",
       "      <td>0.977036</td>\n",
       "      <td>0.973976</td>\n",
       "      <td>0.980116</td>\n",
       "      <td>4042</td>\n",
       "      <td>82</td>\n",
       "      <td>108</td>\n",
       "      <td>725</td>\n",
       "      <td>0.987520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='155' max='155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [155/155 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-05 22:09:41,372] Trial 3 finished with value: 0.9770364998791394 and parameters: {'learning_rate': 1.4369789613249647e-05, 'weight_decay': 0.009247035100297606, 'warmup_ratio': 0.06658598243129632, 'batch_size': 16}. Best is trial 0 with value: 0.9783581187280861.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='389' max='930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [389/930 13:49 < 19:19, 0.47 it/s, Epoch 1.25/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.113466</td>\n",
       "      <td>0.962477</td>\n",
       "      <td>0.977405</td>\n",
       "      <td>0.979309</td>\n",
       "      <td>0.975509</td>\n",
       "      <td>4023</td>\n",
       "      <td>101</td>\n",
       "      <td>85</td>\n",
       "      <td>748</td>\n",
       "      <td>0.986718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-05-05 22:23:35,456] Trial 4 failed with parameters: {'learning_rate': 3.5880789488061963e-05, 'weight_decay': 0.03608788941516705, 'warmup_ratio': 0.1201761323619273, 'batch_size': 16} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/h6/86cprf7s3kxg1526bnp6tn0w0000gn/T/ipykernel_69869/119526113.py\", line 200, in objective\n",
      "    trainer.train()\n",
      "  File \"/Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 2241, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/transformers/trainer.py\", line 2553, in _inner_training_loop\n",
      "    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-05 22:23:35,457] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../content-moderation/data/labeled_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model, tokenizer, optimal_threshold \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Save optimal threshold in model config\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m optimal_threshold\n",
      "Cell \u001b[0;32mIn[14], line 356\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizing hyperparameters...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    355\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 356\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Reduced trials for limited compute\u001b[39;00m\n\u001b[1;32m    358\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[14], line 200\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    190\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    191\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    192\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)]\n\u001b[1;32m    197\u001b[0m )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[1;32m    203\u001b[0m metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/transformers/trainer.py:2553\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../content-moderation/data/labeled_data.csv\")\n",
    "\n",
    "# Train model\n",
    "model, tokenizer, optimal_threshold = main(df)\n",
    "\n",
    "# Save optimal threshold in model config\n",
    "model.config.threshold = optimal_threshold\n",
    "model.save_pretrained(MODEL_DIR)\n",
    "\n",
    "# Example usage\n",
    "sample_tweets = [\n",
    "    \"I love this new app! It's amazing!\",\n",
    "    \"You are so stupid, I hate you\",\n",
    "    \"The weather is nice today :)\",\n",
    "    \"@user This is completely unacceptable behavior #angry\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting final model on sample tweets:\")\n",
    "for tweet in sample_tweets:\n",
    "    result = predict_with_threshold(model, tokenizer, tweet, threshold=optimal_threshold)\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    print(f\"Prediction: {result['class_name']} (confidence: {result['confidence']:.4f})\")\n",
    "    print(f\"Offensive probability: {result['offensive_probability']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model and tokenizer\n",
    "avg_results = {\n",
    "    metric: np.mean([fold[f\"eval_{metric}\"] for fold in fold_results])\n",
    "    for metric in fold_results[0].keys() if metric.startswith(\"eval_\")\n",
    "}\n",
    "\n",
    "print(\"\\nAverage results across folds:\")\n",
    "for metric, value in avg_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Train final model on all data\n",
    "print(\"\\nTraining final model on all data...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace930b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save optimal threshold in model config\n",
    "# model.config.threshold = optimal_threshold\n",
    "model.save_pretrained(MODEL_DIR)\n",
    "\n",
    "# Example usage\n",
    "sample_tweets = [\n",
    "    \"I love this new app! It's amazing!\",\n",
    "    \"You are so stupid, I hate you\",\n",
    "    \"The weather is nice today :)\",\n",
    "    \"@user This is completely unacceptable behavior #angry\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting final model on sample tweets:\")\n",
    "for tweet in sample_tweets:\n",
    "    result = predict_with_threshold(model, tokenizer, tweet, threshold=optimal_threshold)\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    print(f\"Prediction: {result['class_name']} (confidence: {result['confidence']:.4f})\")\n",
    "    print(f\"Offensive probability: {result['offensive_probability']:.4f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
