{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   count               24783 non-null  int64 \n",
      " 1   hate_speech         24783 non-null  int64 \n",
      " 2   offensive_language  24783 non-null  int64 \n",
      " 3   neither             24783 non-null  int64 \n",
      " 4   class               24783 non-null  int64 \n",
      " 5   tweet               24783 non-null  object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  hate_speech  offensive_language  neither  class  \\\n",
       "0          3            0                   0        3      2   \n",
       "1          3            0                   3        0      1   \n",
       "2          3            0                   3        0      1   \n",
       "3          3            0                   2        1      1   \n",
       "4          6            0                   6        0      1   \n",
       "...      ...          ...                 ...      ...    ...   \n",
       "24778      3            0                   2        1      1   \n",
       "24779      3            0                   1        2      2   \n",
       "24780      3            0                   3        0      1   \n",
       "24781      6            0                   6        0      1   \n",
       "24782      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "DATA_FILE = 'data/labeled_data.csv'\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of each classification\n",
    "0 - hate speech \\\n",
    "1 - offensive language \\\n",
    "2 - neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    20620\n",
       "0     4163\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['class'].apply(lambda x: 0 if x == 2 else 1)\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.26.0\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m284.6/284.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from transformers) (2.2.3)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m418.4/418.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl (198 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2025.3.0 huggingface-hub-0.29.3 idna-3.10 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.49.0 urllib3-2.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m342.1/342.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from accelerate) (2.2.3)\n",
      "Requirement already satisfied: psutil in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from accelerate) (0.29.3)\n",
      "Requirement already satisfied: pyyaml in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Collecting torch>=2.0.0\n",
      "  Downloading torch-2.6.0-cp310-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: requests in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, jinja2, torch, accelerate\n",
      "Successfully installed MarkupSafe-3.0.2 accelerate-1.4.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1857' max='1857' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1857/1857 42:45, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.126252</td>\n",
       "      <td>0.945330</td>\n",
       "      <td>0.966440</td>\n",
       "      <td>0.987598</td>\n",
       "      <td>0.946169</td>\n",
       "      <td>3902</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.118114</td>\n",
       "      <td>0.961872</td>\n",
       "      <td>0.976909</td>\n",
       "      <td>0.984487</td>\n",
       "      <td>0.969447</td>\n",
       "      <td>3998</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>0.955417</td>\n",
       "      <td>0.972853</td>\n",
       "      <td>0.985810</td>\n",
       "      <td>0.960233</td>\n",
       "      <td>3960</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.113170</td>\n",
       "      <td>0.963688</td>\n",
       "      <td>0.978271</td>\n",
       "      <td>0.974038</td>\n",
       "      <td>0.982541</td>\n",
       "      <td>4052</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.104679</td>\n",
       "      <td>0.964495</td>\n",
       "      <td>0.978479</td>\n",
       "      <td>0.986926</td>\n",
       "      <td>0.970175</td>\n",
       "      <td>4001</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.102673</td>\n",
       "      <td>0.965907</td>\n",
       "      <td>0.979468</td>\n",
       "      <td>0.981495</td>\n",
       "      <td>0.977449</td>\n",
       "      <td>4031</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.123743</td>\n",
       "      <td>0.966109</td>\n",
       "      <td>0.979631</td>\n",
       "      <td>0.979631</td>\n",
       "      <td>0.979631</td>\n",
       "      <td>4040</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.129087</td>\n",
       "      <td>0.967319</td>\n",
       "      <td>0.980359</td>\n",
       "      <td>0.980359</td>\n",
       "      <td>0.980359</td>\n",
       "      <td>4043</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.126747</td>\n",
       "      <td>0.967319</td>\n",
       "      <td>0.980349</td>\n",
       "      <td>0.980825</td>\n",
       "      <td>0.979874</td>\n",
       "      <td>4041</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [310/310 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation results: {'eval_loss': 0.12908653914928436, 'eval_accuracy': 0.9673189429090175, 'eval_f1': 0.9803588748787585, 'eval_precision': 0.9803588748787585, 'eval_recall': 0.9803588748787585, 'eval_true_positives': 4043, 'eval_false_negatives': 81, 'eval_runtime': 49.3998, 'eval_samples_per_second': 100.344, 'eval_steps_per_second': 6.275, 'epoch': 2.9987898346107302}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    DistilBertForSequenceClassification, \n",
    "    AutoTokenizer,\n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Check for MPS (Apple Silicon) device\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device = torch.device('mps' if use_mps else 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model configuration with smaller memory footprint\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "NUM_LABELS = 2  # Binary classification\n",
    "OUTPUT_DIR = \"./results\"\n",
    "MODEL_DIR = \"./saved_model\"\n",
    "MAX_LENGTH = 128  # Limit sequence length to save memory\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=NUM_LABELS,\n",
    "    id2label={0: \"negative\", 1: \"positive\"}\n",
    ")\n",
    "\n",
    "# Split data with stratification to maintain class distribution\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"tweet\"], \n",
    "    df[\"label\"], \n",
    "    test_size=0.2, \n",
    "    stratify=df[\"label\"],\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Convert to numpy arrays efficiently\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True).to_numpy()\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True).to_numpy()\n",
    "\n",
    "# Memory-efficient dataset implementation\n",
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize on-the-fly instead of storing all tokenized data in memory\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Remove batch dimension added by tokenizer when return_tensors=\"pt\"\n",
    "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        \n",
    "        encoding[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return encoding\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TweetDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
    "val_dataset = TweetDataset(val_texts, val_labels, tokenizer, MAX_LENGTH)\n",
    "\n",
    "# Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, \n",
    "        predictions, \n",
    "        average=\"binary\", \n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"true_positives\": tp,\n",
    "        \"false_negatives\": fn\n",
    "    }\n",
    "\n",
    "# Training hyperparameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,  # test again if not overtrained\n",
    "    per_device_train_batch_size=8,  # keep small for cpu \n",
    "    per_device_eval_batch_size=16,  # keep small for cpu\n",
    "    gradient_accumulation_steps=4,  # accumulate gradients to simulate larger batch\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    evaluation_strategy=\"epochs\",\n",
    "    save_total_limit=2,  # keep fewer checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=0,  # disable multiprocessing to reduce memory usage\n",
    "    seed=RANDOM_SEED,\n",
    "    optim=\"adamw_torch\"  # Use PyTorch's native optimizer which can be more memory efficient\n",
    ")\n",
    "\n",
    "# Initialize trainer with early stopping\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Final evaluation results: {eval_results}\")\n",
    "\n",
    "# Save the model and tokenizer\n",
    "trainer.save_model(MODEL_DIR)\n",
    "tokenizer.save_pretrained(MODEL_DIR)\n",
    "\n",
    "# Interface to predict sentiment using the model\n",
    "def predict_sentiment(text):\n",
    "    # Process one example at a time\n",
    "    inputs = tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True, \n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the right device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Use inference mode to save memory\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits.cpu()  # Move back to CPU for post-processing\n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"predicted_class\": prediction,\n",
    "        \"class_name\": model.config.id2label[prediction],\n",
    "        \"confidence\": torch.softmax(logits, dim=-1)[0][prediction].item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilghosh/Documents/Visual Studio Code/Courses/cse3000-ethics/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    DistilBertForSequenceClassification, \n",
    "    AutoTokenizer,\n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Check for MPS (Apple Silicon) device\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "try:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS device\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA device\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU device\")\n",
    "except:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Fallback to CPU device due to error\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model configuration with smaller memory footprint\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "NUM_LABELS = 2  # Binary classification\n",
    "OUTPUT_DIR = \"./results\"\n",
    "MODEL_DIR = \"./saved_model\"\n",
    "MAX_LENGTH = 128  # Limit sequence length to save memory\n",
    "\n",
    "\n",
    "MODEL_DIR = \"./saved_model\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    # Process one example at a time\n",
    "    inputs = tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True, \n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the right device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Use inference mode to save memory\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits.cpu()  # Move back to CPU for post-processing\n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"predicted_class\": prediction,\n",
    "        \"class_name\": model.config.id2label[prediction],\n",
    "        \"confidence\": torch.softmax(logits, dim=-1)[0][prediction].item()\n",
    "    }\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I like candy and toys',\n",
       " 'predicted_class': 0,\n",
       " 'class_name': 'negative',\n",
       " 'confidence': 0.9962435960769653}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = \"I like candy and toys\"\n",
    "predict_sentiment(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
